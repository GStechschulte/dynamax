{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank Gaussian Hidden Markov Model (HMM)\n",
    "\n",
    "Hidden Markov Models (HMMs) assume that our $X$ observations can be explained by set of hidden state variable, $z$, each which can take on one of $K$ discrete values. \n",
    "That is, we assume that we have $z_t \\in \\{1, \\ldots, K\\}$, where $z_t = k$ denotes that the hidden variable is in state $k$ at time $t$.\n",
    "\n",
    "We further assume that this hidden state evolves over time $t$ with some set of transition probabilities.\n",
    "The key assumption in an HMM is that only the most recent state affects the next state: \n",
    "\n",
    "$$\n",
    "p(z_t \\mid z_{t-1}, z_{t-2}, \\ldots, z_1) = p(z_t \\mid z_{t-1})\n",
    "$$\n",
    "\n",
    "Importantly, we don't observe the state $z_t$ itself; instead, we get a noisy observation of the state at each time step according to some observation model.\n",
    "We'll use $x_t$ to denote the observation at time step $t$ and use $D$ to refer to the dimensionality of the observation, since this can be either a vector or scalar.\n",
    "\n",
    "In a Gaussian HMM, each discrete state $z_t = k$, is associated with a $D$-dimensional mean $\\mu_k$ and covariance matrix $\\Sigma_k$ which jointly determine the _emission probability distribution_. Thus, each probability distribution is a Gaussian centered at $\\mu_k$ and with covariance $\\Sigma_k$.\n",
    "\n",
    "Low-rank Gaussian HMMs further assume that each covariance matrix of our Gaussian emission probabilities is _low-rank_; that is, that it can be well-modelled as a perturbation of a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying low-rank Gaussian HMMs\n",
    "\n",
    "Our goal in using low-rank Gaussian HMMs is to better reflect the our understanding of the underlying state dynamics&mdash;particularly when we believe several independent factors are involved.\n",
    "\n",
    "In this tutorial, we'll explore these ideas in a two dimensional space for easy visualization.\n",
    "First, we'll import the SSM-JAX library as well as a few other useful modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from itertools import count\n",
    "\n",
    "from ssm_jax.hmm import MultivariateNormalDiagPlusLowRankHMM as LowRankHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define a low-rank Gaussian HMM instance.\n",
    "To do this, we'll need to decide on the number of states $K$ in our model, as well as the dimensionality of our emission distributions, $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants used to define the HMM\n",
    "num_states = 5\n",
    "emission_dim = 2\n",
    "emission_cov_rank = 2\n",
    "\n",
    "# Defined number of times to sample from the HMM\n",
    "num_timesteps = 2000\n",
    "\n",
    "# Set up an iterator to yield JAX PRNGKey's\n",
    "keys = map(jr.PRNGKey, count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these, we can randomly initialize a Gaussian low-rank HMM instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hmm = LowRankHMM.random_initialization(\n",
    "    next(keys), num_states, emission_dim, emission_cov_rank)\n",
    "true_states, emissions = lr_hmm.sample(next(keys), num_timesteps)\n",
    "\n",
    "# we can print our initialized emission covariance matrices;\n",
    "# these should be low rank !\n",
    "print(lr_hmm.emission_covariance_matrices.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After drawing 2000 samples from this low-rank Gaussian HMM, we have an array `true_states` of size $(2000,)$ which contains the true discrete state $z_t = k$ for each of our $t$ time steps.\n",
    "We also have an array `emissions` of size $(2000, 2)$ which contains the 2000 observations from our low-rank Gaussian HMM, where each observation is of $D$ dimensions&mdash;in our case, two.\n",
    "\n",
    "We'll next use these `true_states` and `emissions` variables to plot our emissions distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ssm_jax.plotting import COLORS\n",
    "from ssm_jax.plotting import white_to_color_cmap\n",
    "\n",
    "lim = 0.85 * abs(emissions).max()\n",
    "XX, YY = jnp.meshgrid(jnp.linspace(-lim, lim, 100), jnp.linspace(-lim, lim, 100))\n",
    "grid = jnp.column_stack((XX.ravel(), YY.ravel()))\n",
    "\n",
    "plt.figure()\n",
    "for k in range(lr_hmm.num_states):\n",
    "    lls = lr_hmm.emission_distribution(k).log_prob(grid)\n",
    "    plt.contour(XX, YY, jnp.exp(lls).reshape(XX.shape),\n",
    "                cmap=white_to_color_cmap(COLORS[k]))\n",
    "    plt.plot(emissions[true_states == k, 0],\n",
    "             emissions[true_states == k, 1],\n",
    "             \"o\", mfc=COLORS[k], mec=\"none\", ms=3, alpha=0.5)\n",
    "\n",
    "plt.plot(emissions[:, 0], emissions[:, 1], \"-k\", lw=1, alpha=0.25)\n",
    "plt.xlabel(\"$y_1$\")\n",
    "plt.ylabel(\"$y_2$\")\n",
    "plt.title(\"Emission Distributions\")\n",
    "plt.tight_layout()\n",
    "plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the data superimposed on the generating state sequence to see the relationship between our each of the $D$ dimensions of our observations and the underlying states $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssm_jax.plotting import CMAP\n",
    "\n",
    "plot_timesteps = 200\n",
    "num_timesteps = len(emissions)\n",
    "emission_dim = lr_hmm.num_obs\n",
    "\n",
    "plt.figure()\n",
    "lim = 1.05 * abs(emissions).max()\n",
    "plt.imshow(\n",
    "    true_states[None, :], aspect=\"auto\",\n",
    "    interpolation=\"none\", cmap=CMAP,\n",
    "    vmin=0, vmax=len(COLORS) - 1,\n",
    "    extent=(0, num_timesteps, -lim, emission_dim * lim),\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "means = lr_hmm.emission_means.value[true_states]\n",
    "for d in range(emission_dim):\n",
    "    plt.plot(emissions[:, d] + lim * d, \"-k\")\n",
    "    plt.plot(means[:, d] + lim * d, \":k\")\n",
    "\n",
    "plt.xlim(0, num_timesteps)\n",
    "plt.xlabel(\"time\")\n",
    "plt.yticks(lim * jnp.arange(emission_dim), [\"$y_{}$\".format(d + 1) for d in range(emission_dim)])\n",
    "\n",
    "plt.title(\"Simulated data from an HMM\")\n",
    "plt.tight_layout()\n",
    "plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b02e0b02a80c3c1bc67fbc52ae58f5bbbe1f1c7c93520e6e32ea85448585eea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
